layer {
  name: "data"
  type: "CPMData"
  top: "data"
  top: "label"
  data_param {
    source: "/data/xiaobing.wang/pose/COCO_kpt_train_8000/lmdb/"
    batch_size: 8
    backend: LMDB
  }
  cpm_transform_param {
    stride: 8
    max_rotate_degree: 40.0
    visualize: false
    crop_size_x: 368
    crop_size_y: 368
    scale_prob: 1.0
    scale_min: 0.5
    scale_max: 1.10000002384
    target_dist: 0.600000023842
    center_perterb_max: 40.0
    do_clahe: false
    num_parts: 56
    np_in_lmdb: 17
  }
}
layer {
  name: "vec_weight"
  type: "Slice"
  bottom: "label"
  top: "vec_weight"
  top: "heat_weight"
  top: "vec_temp"
  top: "heat_temp"
  slice_param {
    slice_point: 38
    slice_point: 57
    slice_point: 95
    axis: 1
  }
}
layer {
  name: "label_vec"
  type: "Eltwise"
  bottom: "vec_weight"
  bottom: "vec_temp"
  top: "label_vec"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "label_heat"
  type: "Eltwise"
  bottom: "heat_weight"
  bottom: "heat_temp"
  top: "label_heat"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "image"
  type: "Slice"
  bottom: "data"
  top: "image"
  top: "center_map"
  slice_param {
    slice_point: 3
    axis: 1
  }
}
layer {
  name: "silence2"
  type: "Silence"
  bottom: "center_map"
}
#================================ ResNet-50 conv4 conv5 dilation bn open ===============================================
# ------------------------ conv1 -----------------------------
layer {
    bottom: "image"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 7
        pad: 3
        stride: 2
    }
    param {
        lr_mult: 0.0
    }
    param {
        lr_mult: 0.0
    }
    
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
}

layer {
    bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
        kernel_size: 3
        stride: 2
        pool: MAX
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "res2a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2c"
    name: "res2a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2c"
    top: "res2a_branch2c"
    name: "bn2a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2c"
    top: "res2a_branch2c"
    name: "scale2a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2c"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
}

layer {
    bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "res2b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2c"
    name: "res2b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2c"
    top: "res2b_branch2c"
    name: "bn2b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2c"
    top: "res2b_branch2c"
    name: "scale2b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a"
    bottom: "res2b_branch2c"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
}

layer {
    bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b"
    top: "res2c_branch2a"
    name: "res2c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2a"
    name: "bn2c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2a"
    name: "scale2c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2a"
    name: "res2c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2b"
    name: "res2c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2b"
    name: "bn2c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2b"
    name: "scale2c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2b"
    name: "res2c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2c"
    name: "res2c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2c"
    top: "res2c_branch2c"
    name: "bn2c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2c"
    top: "res2c_branch2c"
    name: "scale2c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b"
    bottom: "res2c_branch2c"
    top: "res2c"
    name: "res2c"
    type: "Eltwise"
}

layer {
    bottom: "res2c"
    top: "res2c"
    name: "res2c_relu"
    type: "ReLU"
}

layer {
    bottom: "res2c"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 2
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2c"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 2
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "res3a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2c"
    name: "res3a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch2c"
    top: "res3a_branch2c"
    name: "bn3a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2c"
    top: "res3a_branch2c"
    name: "scale3a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch1"
    bottom: "res3a_branch2c"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
}

layer {
    bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "res3b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2c"
    name: "res3b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3b_branch2c"
    top: "res3b_branch2c"
    name: "bn3b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2c"
    top: "res3b_branch2c"
    name: "scale3b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a"
    bottom: "res3b_branch2c"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
}

layer {
    bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b"
    top: "res3c_branch2a"
    name: "res3c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2a"
    name: "bn3c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2a"
    name: "scale3c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2a"
    name: "res3c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2b"
    name: "res3c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2b"
    name: "bn3c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2b"
    name: "scale3c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2b"
    name: "res3c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2c"
    name: "res3c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3c_branch2c"
    top: "res3c_branch2c"
    name: "bn3c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2c"
    top: "res3c_branch2c"
    name: "scale3c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b"
    bottom: "res3c_branch2c"
    top: "res3c"
    name: "res3c"
    type: "Eltwise"
}

layer {
    bottom: "res3c"
    top: "res3c"
    name: "res3c_relu"
    type: "ReLU"
}

layer {
    bottom: "res3c"
    top: "res3d_branch2a"
    name: "res3d_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2a"
    name: "bn3d_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2a"
    name: "scale3d_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2a"
    name: "res3d_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2b"
    name: "res3d_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2b"
    name: "bn3d_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2b"
    name: "scale3d_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2b"
    name: "res3d_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2c"
    name: "res3d_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3d_branch2c"
    top: "res3d_branch2c"
    name: "bn3d_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2c"
    top: "res3d_branch2c"
    name: "scale3d_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3c"
    bottom: "res3d_branch2c"
    top: "res3d"
    name: "res3d"
    type: "Eltwise"
}

layer {
    bottom: "res3d"
    top: "res3d"
    name: "res3d_relu"
    type: "ReLU"
}



layer {
    bottom: "res3d"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3d"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "res4a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2c"
    name: "res4a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch2c"
    top: "res4a_branch2c"
    name: "bn4a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2c"
    top: "res4a_branch2c"
    name: "scale4a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch1"
    bottom: "res4a_branch2c"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
}

layer {
    bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "res4b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2c"
    name: "res4b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4b_branch2c"
    top: "res4b_branch2c"
    name: "bn4b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2c"
    top: "res4b_branch2c"
    name: "scale4b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a"
    bottom: "res4b_branch2c"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
}

layer {
    bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b"
    top: "res4c_branch2a"
    name: "res4c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2a"
    name: "bn4c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2a"
    name: "scale4c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2a"
    name: "res4c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2b"
    name: "res4c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2b"
    name: "bn4c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2b"
    name: "scale4c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2b"
    name: "res4c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2c"
    name: "res4c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4c_branch2c"
    top: "res4c_branch2c"
    name: "bn4c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2c"
    top: "res4c_branch2c"
    name: "scale4c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b"
    bottom: "res4c_branch2c"
    top: "res4c"
    name: "res4c"
    type: "Eltwise"
}

layer {
    bottom: "res4c"
    top: "res4c"
    name: "res4c_relu"
    type: "ReLU"
}

layer {
    bottom: "res4c"
    top: "res4d_branch2a"
    name: "res4d_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2a"
    name: "bn4d_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2a"
    name: "scale4d_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2a"
    name: "res4d_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2b"
    name: "res4d_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2b"
    name: "bn4d_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2b"
    name: "scale4d_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2b"
    name: "res4d_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2c"
    name: "res4d_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4d_branch2c"
    top: "res4d_branch2c"
    name: "bn4d_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2c"
    top: "res4d_branch2c"
    name: "scale4d_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4c"
    bottom: "res4d_branch2c"
    top: "res4d"
    name: "res4d"
    type: "Eltwise"
}

layer {
    bottom: "res4d"
    top: "res4d"
    name: "res4d_relu"
    type: "ReLU"
}

layer {
    bottom: "res4d"
    top: "res4e_branch2a"
    name: "res4e_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2a"
    name: "bn4e_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2a"
    name: "scale4e_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2a"
    name: "res4e_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2b"
    name: "res4e_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2b"
    name: "bn4e_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2b"
    name: "scale4e_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2b"
    name: "res4e_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2c"
    name: "res4e_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4e_branch2c"
    top: "res4e_branch2c"
    name: "bn4e_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2c"
    top: "res4e_branch2c"
    name: "scale4e_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4d"
    bottom: "res4e_branch2c"
    top: "res4e"
    name: "res4e"
    type: "Eltwise"
}

layer {
    bottom: "res4e"
    top: "res4e"
    name: "res4e_relu"
    type: "ReLU"
}

layer {
    bottom: "res4e"
    top: "res4f_branch2a"
    name: "res4f_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2a"
    name: "bn4f_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2a"
    name: "scale4f_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2a"
    name: "res4f_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2b"
    name: "res4f_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2b"
    name: "bn4f_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2b"
    name: "scale4f_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2b"
    name: "res4f_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2c"
    name: "res4f_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4f_branch2c"
    top: "res4f_branch2c"
    name: "bn4f_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2c"
    top: "res4f_branch2c"
    name: "scale4f_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4e"
    bottom: "res4f_branch2c"
    top: "res4f"
    name: "res4f"
    type: "Eltwise"
}

layer {
    bottom: "res4f"
    top: "res4f"
    name: "res4f_relu"
    type: "ReLU"
}

layer {
    bottom: "res4f"
    top: "res5a_branch1"
    name: "res5a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "bn5a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "scale5a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4f"
    top: "res5a_branch2a"
    name: "res5a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "bn5a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "scale5a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "res5a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2b"
    name: "res5a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 4
        pad: 4
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "bn5a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "scale5a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "res5a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2c"
    name: "res5a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch2c"
    top: "res5a_branch2c"
    name: "bn5a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2c"
    top: "res5a_branch2c"
    name: "scale5a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch1"
    bottom: "res5a_branch2c"
    top: "res5a"
    name: "res5a"
    type: "Eltwise"
}

layer {
    bottom: "res5a"
    top: "res5a"
    name: "res5a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a"
    top: "res5b_branch2a"
    name: "res5b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "bn5b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "scale5b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "res5b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2b"
    name: "res5b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 4
        pad: 4
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "bn5b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "scale5b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "res5b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2c"
    name: "res5b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5b_branch2c"
    top: "res5b_branch2c"
    name: "bn5b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2c"
    top: "res5b_branch2c"
    name: "scale5b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a"
    bottom: "res5b_branch2c"
    top: "res5b"
    name: "res5b"
    type: "Eltwise"
}

layer {
    bottom: "res5b"
    top: "res5b"
    name: "res5b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b"
    top: "res5c_branch2a"
    name: "res5c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2a"
    name: "bn5c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2a"
    name: "scale5c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2a"
    name: "res5c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2b"
    name: "res5c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 4
        pad: 4
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2b"
    name: "bn5c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2b"
    name: "scale5c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2b"
    name: "res5c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2c"
    name: "res5c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5c_branch2c"
    top: "res5c_branch2c"
    name: "bn5c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
    param {
        lr_mult: 1.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2c"
    top: "res5c_branch2c"
    name: "scale5c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5b"
    bottom: "res5c_branch2c"
    top: "res5c"
    name: "res5c"
    type: "Eltwise"
}

layer {
    bottom: "res5c"
    top: "res5c"
    name: "res5c_relu"
    type: "ReLU"
}
##==============================================================================================================
#
layer {
  name: "res5c_new"
  type: "Convolution"
  bottom: "res5c"
  top: "res5c_new"
  param {
    lr_mult: 1.0
    decay_mult: 1
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "res5c_new_relu"
  type: "ReLU"
  bottom: "res5c_new"
  top: "res5c_new"
}


#layer {
#  name: "silence3"
#  type: "Silence"
#  bottom: "res5c_new"
#}

#==============================================================================================================
#
layer {
  name: "conv5_1_CPM"
  type: "Convolution"
  bottom: "res5c_new" #"res5c_new"
  top: "conv5_1_CPM"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_1_CPM"
  type: "ReLU"
  bottom: "conv5_1_CPM"
  top: "conv5_1_CPM"
}

layer {
  name: "conv5_2_CPM"
  type: "Convolution"
  bottom: "conv5_1_CPM"
  top: "conv5_2_CPM"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_2_CPM"
  type: "ReLU"
  bottom: "conv5_2_CPM"
  top: "conv5_2_CPM"
}

layer {
  name: "conv5_3_CPM"
  type: "Convolution"
  bottom: "conv5_2_CPM"
  top: "conv5_3_CPM"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_3_CPM"
  type: "ReLU"
  bottom: "conv5_3_CPM"
  top: "conv5_3_CPM"
}

layer {
  name: "conv5_4_CPM"
  type: "Convolution"
  bottom: "conv5_3_CPM"
  top: "conv5_4_CPM"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_4_CPM"
  type: "ReLU"
  bottom: "conv5_4_CPM"
  top: "conv5_4_CPM"
}


layer {
  name: "conv5_5_CPM_L1"
  type: "Convolution"
  bottom: "conv5_4_CPM"
  top: "conv5_5_CPM_L1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 38
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_5_CPM_L2"
  type: "Convolution"
  bottom: "conv5_4_CPM"
  top: "conv5_5_CPM_L2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 19
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "weight_stage1_L1"
  type: "Eltwise"
  bottom: "conv5_5_CPM_L1"
  bottom: "vec_weight"
  top: "weight_stage1_L1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "loss_stage1_L1"
  type: "EuclideanLoss"
  bottom: "weight_stage1_L1"
  bottom: "label_vec"
  top: "loss_stage1_L1"
  loss_weight: 1.0
}
layer {
  name: "weight_stage1_L2"
  type: "Eltwise"
  bottom: "conv5_5_CPM_L2"
  bottom: "heat_weight"
  top: "weight_stage1_L2"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "loss_stage1_L2"
  type: "EuclideanLoss"
  bottom: "weight_stage1_L2"
  bottom: "label_heat"
  top: "loss_stage1_L2"
  loss_weight: 1.0
}
layer {
  name: "concat_stage2"
  type: "Concat"
  bottom: "conv5_5_CPM_L1"
  bottom: "conv5_5_CPM_L2"
  bottom: "res5c_new"
  top: "concat_stage2"
  concat_param {
    axis: 1
  }
}

layer {
  name: "Mconv1_stage2"
  type: "Convolution"
  bottom: "concat_stage2"
  top: "Mconv1_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mrelu1_stage2"
  type: "ReLU"
  bottom: "Mconv1_stage2"
  top: "Mconv1_stage2"
}

layer {
  name: "Mconv2_stage2"
  type: "Convolution"
  bottom: "Mconv1_stage2"
  top: "Mconv2_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mrelu2_stage2"
  type: "ReLU"
  bottom: "Mconv2_stage2"
  top: "Mconv2_stage2"
}

layer {
  name: "Mconv3_stage2"
  type: "Convolution"
  bottom: "Mconv2_stage2"
  top: "Mconv3_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mrelu3_stage2"
  type: "ReLU"
  bottom: "Mconv3_stage2"
  top: "Mconv3_stage2"
}

layer {
  name: "Mconv4_stage2"
  type: "Convolution"
  bottom: "Mconv3_stage2"
  top: "Mconv4_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mrelu4_stage2"
  type: "ReLU"
  bottom: "Mconv4_stage2"
  top: "Mconv4_stage2"
}

layer {
  name: "Mconv5_stage2"
  type: "Convolution"
  bottom: "Mconv4_stage2"
  top: "Mconv5_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 3
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mrelu5_stage2"
  type: "ReLU"
  bottom: "Mconv5_stage2"
  top: "Mconv5_stage2"
}

layer {
  name: "Mconv6_stage2"
  type: "Convolution"
  bottom: "Mconv5_stage2"
  top: "Mconv6_stage2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mrelu6_stage2"
  type: "ReLU"
  bottom: "Mconv6_stage2"
  top: "Mconv6_stage2"
}


layer {
  name: "Mconv7_stage2_L1"
  type: "Convolution"
  bottom: "Mconv6_stage2"
  top: "Mconv7_stage2_L1"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 38
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Mconv7_stage2_L2"
  type: "Convolution"
  bottom: "Mconv6_stage2"
  top: "Mconv7_stage2_L2"
  param {
    lr_mult: 4.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 8.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 19
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "weight_stage2_L1"
  type: "Eltwise"
  bottom: "Mconv7_stage2_L1"
  bottom: "vec_weight"
  top: "weight_stage2_L1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "loss_stage2_L1"
  type: "EuclideanLoss"
  bottom: "weight_stage2_L1"
  bottom: "label_vec"
  top: "loss_stage2_L1"
  loss_weight: 1.0
}
layer {
  name: "weight_stage2_L2"
  type: "Eltwise"
  bottom: "Mconv7_stage2_L2"
  bottom: "heat_weight"
  top: "weight_stage2_L2"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "loss_stage2_L2"
  type: "EuclideanLoss"
  bottom: "weight_stage2_L2"
  bottom: "label_heat"
  top: "loss_stage2_L2"
  loss_weight: 1.0
}



#layer {
#  name: "concat_stage3"
#  type: "Concat"
#  bottom: "Mconv7_stage2_L1"
#  bottom: "Mconv7_stage2_L2"
#  bottom: "res5c_new"
#  top: "concat_stage3"
#  concat_param {
#    axis: 1
#  }
#}
#
#layer {
#  name: "Mconv1_stage3"
#  type: "Convolution"
#  bottom: "concat_stage3"
#  top: "Mconv1_stage3"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu1_stage3"
#  type: "ReLU"
#  bottom: "Mconv1_stage3"
#  top: "Mconv1_stage3"
#}
#
#layer {
#  name: "Mconv2_stage3"
#  type: "Convolution"
#  bottom: "Mconv1_stage3"
#  top: "Mconv2_stage3"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu2_stage3"
#  type: "ReLU"
#  bottom: "Mconv2_stage3"
#  top: "Mconv2_stage3"
#}
#
#layer {
#  name: "Mconv3_stage3"
#  type: "Convolution"
#  bottom: "Mconv2_stage3"
#  top: "Mconv3_stage3"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu3_stage3"
#  type: "ReLU"
#  bottom: "Mconv3_stage3"
#  top: "Mconv3_stage3"
#}
#
#layer {
#  name: "Mconv4_stage3"
#  type: "Convolution"
#  bottom: "Mconv3_stage3"
#  top: "Mconv4_stage3"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu4_stage3"
#  type: "ReLU"
#  bottom: "Mconv4_stage3"
#  top: "Mconv4_stage3"
#}
#
#layer {
#  name: "Mconv5_stage3"
#  type: "Convolution"
#  bottom: "Mconv4_stage3"
#  top: "Mconv5_stage3"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu5_stage3"
#  type: "ReLU"
#  bottom: "Mconv5_stage3"
#  top: "Mconv5_stage3"
#}
#
#layer {
#  name: "Mconv6_stage3"
#  type: "Convolution"
#  bottom: "Mconv5_stage3"
#  top: "Mconv6_stage3"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu6_stage3"
#  type: "ReLU"
#  bottom: "Mconv6_stage3"
#  top: "Mconv6_stage3"
#}
#
#
#layer {
#  name: "Mconv7_stage3_L1"
#  type: "Convolution"
#  bottom: "Mconv6_stage3"
#  top: "Mconv7_stage3_L1"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 38
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mconv7_stage3_L2"
#  type: "Convolution"
#  bottom: "Mconv6_stage3"
#  top: "Mconv7_stage3_L2"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 19
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "weight_stage3_L1"
#  type: "Eltwise"
#  bottom: "Mconv7_stage3_L1"
#  bottom: "vec_weight"
#  top: "weight_stage3_L1"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage3_L1"
#  type: "EuclideanLoss"
#  bottom: "weight_stage3_L1"
#  bottom: "label_vec"
#  top: "loss_stage3_L1"
#  loss_weight: 1.0
#}
#layer {
#  name: "weight_stage3_L2"
#  type: "Eltwise"
#  bottom: "Mconv7_stage3_L2"
#  bottom: "heat_weight"
#  top: "weight_stage3_L2"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage3_L2"
#  type: "EuclideanLoss"
#  bottom: "weight_stage3_L2"
#  bottom: "label_heat"
#  top: "loss_stage3_L2"
#  loss_weight: 1.0
#}
#
#layer {
#  name: "concat_stage4"
#  type: "Concat"
#  bottom: "Mconv7_stage3_L1"
#  bottom: "Mconv7_stage3_L2"
#  bottom: "res5c_new"
#  top: "concat_stage4"
#  concat_param {
#    axis: 1
#  }
#}
#
#layer {
#  name: "Mconv1_stage4"
#  type: "Convolution"
#  bottom: "concat_stage4"
#  top: "Mconv1_stage4"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu1_stage4"
#  type: "ReLU"
#  bottom: "Mconv1_stage4"
#  top: "Mconv1_stage4"
#}
#
#layer {
#  name: "Mconv2_stage4"
#  type: "Convolution"
#  bottom: "Mconv1_stage4"
#  top: "Mconv2_stage4"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu2_stage4"
#  type: "ReLU"
#  bottom: "Mconv2_stage4"
#  top: "Mconv2_stage4"
#}
#
#layer {
#  name: "Mconv3_stage4"
#  type: "Convolution"
#  bottom: "Mconv2_stage4"
#  top: "Mconv3_stage4"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu3_stage4"
#  type: "ReLU"
#  bottom: "Mconv3_stage4"
#  top: "Mconv3_stage4"
#}
#
#layer {
#  name: "Mconv4_stage4"
#  type: "Convolution"
#  bottom: "Mconv3_stage4"
#  top: "Mconv4_stage4"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu4_stage4"
#  type: "ReLU"
#  bottom: "Mconv4_stage4"
#  top: "Mconv4_stage4"
#}
#
#layer {
#  name: "Mconv5_stage4"
#  type: "Convolution"
#  bottom: "Mconv4_stage4"
#  top: "Mconv5_stage4"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu5_stage4"
#  type: "ReLU"
#  bottom: "Mconv5_stage4"
#  top: "Mconv5_stage4"
#}
#
#layer {
#  name: "Mconv6_stage4"
#  type: "Convolution"
#  bottom: "Mconv5_stage4"
#  top: "Mconv6_stage4"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu6_stage4"
#  type: "ReLU"
#  bottom: "Mconv6_stage4"
#  top: "Mconv6_stage4"
#}
#
#
#layer {
#  name: "Mconv7_stage4_L1"
#  type: "Convolution"
#  bottom: "Mconv6_stage4"
#  top: "Mconv7_stage4_L1"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 38
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mconv7_stage4_L2"
#  type: "Convolution"
#  bottom: "Mconv6_stage4"
#  top: "Mconv7_stage4_L2"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 19
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "weight_stage4_L1"
#  type: "Eltwise"
#  bottom: "Mconv7_stage4_L1"
#  bottom: "vec_weight"
#  top: "weight_stage4_L1"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage4_L1"
#  type: "EuclideanLoss"
#  bottom: "weight_stage4_L1"
#  bottom: "label_vec"
#  top: "loss_stage4_L1"
#  loss_weight: 1.0
#}
#layer {
#  name: "weight_stage4_L2"
#  type: "Eltwise"
#  bottom: "Mconv7_stage4_L2"
#  bottom: "heat_weight"
#  top: "weight_stage4_L2"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage4_L2"
#  type: "EuclideanLoss"
#  bottom: "weight_stage4_L2"
#  bottom: "label_heat"
#  top: "loss_stage4_L2"
#  loss_weight: 1.0
#}
#
#layer {
#  name: "concat_stage5"
#  type: "Concat"
#  bottom: "Mconv7_stage4_L1"
#  bottom: "Mconv7_stage4_L2"
#  bottom: "res5c_new"
#  top: "concat_stage5"
#  concat_param {
#    axis: 1
#  }
#}
#
#layer {
#  name: "Mconv1_stage5"
#  type: "Convolution"
#  bottom: "concat_stage5"
#  top: "Mconv1_stage5"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu1_stage5"
#  type: "ReLU"
#  bottom: "Mconv1_stage5"
#  top: "Mconv1_stage5"
#}
#
#layer {
#  name: "Mconv2_stage5"
#  type: "Convolution"
#  bottom: "Mconv1_stage5"
#  top: "Mconv2_stage5"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu2_stage5"
#  type: "ReLU"
#  bottom: "Mconv2_stage5"
#  top: "Mconv2_stage5"
#}
#
#layer {
#  name: "Mconv3_stage5"
#  type: "Convolution"
#  bottom: "Mconv2_stage5"
#  top: "Mconv3_stage5"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu3_stage5"
#  type: "ReLU"
#  bottom: "Mconv3_stage5"
#  top: "Mconv3_stage5"
#}
#
#layer {
#  name: "Mconv4_stage5"
#  type: "Convolution"
#  bottom: "Mconv3_stage5"
#  top: "Mconv4_stage5"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu4_stage5"
#  type: "ReLU"
#  bottom: "Mconv4_stage5"
#  top: "Mconv4_stage5"
#}
#
#layer {
#  name: "Mconv5_stage5"
#  type: "Convolution"
#  bottom: "Mconv4_stage5"
#  top: "Mconv5_stage5"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu5_stage5"
#  type: "ReLU"
#  bottom: "Mconv5_stage5"
#  top: "Mconv5_stage5"
#}
#
#layer {
#  name: "Mconv6_stage5"
#  type: "Convolution"
#  bottom: "Mconv5_stage5"
#  top: "Mconv6_stage5"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu6_stage5"
#  type: "ReLU"
#  bottom: "Mconv6_stage5"
#  top: "Mconv6_stage5"
#}
#
#
#layer {
#  name: "Mconv7_stage5_L1"
#  type: "Convolution"
#  bottom: "Mconv6_stage5"
#  top: "Mconv7_stage5_L1"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 38
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mconv7_stage5_L2"
#  type: "Convolution"
#  bottom: "Mconv6_stage5"
#  top: "Mconv7_stage5_L2"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 19
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "weight_stage5_L1"
#  type: "Eltwise"
#  bottom: "Mconv7_stage5_L1"
#  bottom: "vec_weight"
#  top: "weight_stage5_L1"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage5_L1"
#  type: "EuclideanLoss"
#  bottom: "weight_stage5_L1"
#  bottom: "label_vec"
#  top: "loss_stage5_L1"
#  loss_weight: 1.0
#}
#layer {
#  name: "weight_stage5_L2"
#  type: "Eltwise"
#  bottom: "Mconv7_stage5_L2"
#  bottom: "heat_weight"
#  top: "weight_stage5_L2"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage5_L2"
#  type: "EuclideanLoss"
#  bottom: "weight_stage5_L2"
#  bottom: "label_heat"
#  top: "loss_stage5_L2"
#  loss_weight: 1.0
#}
#
#layer {
#  name: "concat_stage6"
#  type: "Concat"
#  bottom: "Mconv7_stage5_L1"
#  bottom: "Mconv7_stage5_L2"
#  bottom: "res5c_new"
#  top: "concat_stage6"
#  concat_param {
#    axis: 1
#  }
#}
#
#layer {
#  name: "Mconv1_stage6"
#  type: "Convolution"
#  bottom: "concat_stage6"
#  top: "Mconv1_stage6"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu1_stage6"
#  type: "ReLU"
#  bottom: "Mconv1_stage6"
#  top: "Mconv1_stage6"
#}
#
#layer {
#  name: "Mconv2_stage6"
#  type: "Convolution"
#  bottom: "Mconv1_stage6"
#  top: "Mconv2_stage6"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu2_stage6"
#  type: "ReLU"
#  bottom: "Mconv2_stage6"
#  top: "Mconv2_stage6"
#}
#
#layer {
#  name: "Mconv3_stage6"
#  type: "Convolution"
#  bottom: "Mconv2_stage6"
#  top: "Mconv3_stage6"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu3_stage6"
#  type: "ReLU"
#  bottom: "Mconv3_stage6"
#  top: "Mconv3_stage6"
#}
#
#layer {
#  name: "Mconv4_stage6"
#  type: "Convolution"
#  bottom: "Mconv3_stage6"
#  top: "Mconv4_stage6"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu4_stage6"
#  type: "ReLU"
#  bottom: "Mconv4_stage6"
#  top: "Mconv4_stage6"
#}
#
#layer {
#  name: "Mconv5_stage6"
#  type: "Convolution"
#  bottom: "Mconv4_stage6"
#  top: "Mconv5_stage6"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 3
#    kernel_size: 7
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu5_stage6"
#  type: "ReLU"
#  bottom: "Mconv5_stage6"
#  top: "Mconv5_stage6"
#}
#
#layer {
#  name: "Mconv6_stage6"
#  type: "Convolution"
#  bottom: "Mconv5_stage6"
#  top: "Mconv6_stage6"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 128
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mrelu6_stage6"
#  type: "ReLU"
#  bottom: "Mconv6_stage6"
#  top: "Mconv6_stage6"
#}
#
#
#layer {
#  name: "Mconv7_stage6_L1"
#  type: "Convolution"
#  bottom: "Mconv6_stage6"
#  top: "Mconv7_stage6_L1"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 38
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "Mconv7_stage6_L2"
#  type: "Convolution"
#  bottom: "Mconv6_stage6"
#  top: "Mconv7_stage6_L2"
#  param {
#    lr_mult: 4.0
#    decay_mult: 1.0
#  }
#  param {
#    lr_mult: 8.0
#    decay_mult: 0.0
#  }
#  convolution_param {
#    num_output: 19
#    pad: 0
#    kernel_size: 1
#    weight_filler {
#      type: "gaussian"
#      std: 0.00999999977648
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "weight_stage6_L1"
#  type: "Eltwise"
#  bottom: "Mconv7_stage6_L1"
#  bottom: "vec_weight"
#  top: "weight_stage6_L1"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage6_L1"
#  type: "EuclideanLoss"
#  bottom: "weight_stage6_L1"
#  bottom: "label_vec"
#  top: "loss_stage6_L1"
#  loss_weight: 1.0
#}
#layer {
#  name: "weight_stage6_L2"
#  type: "Eltwise"
#  bottom: "Mconv7_stage6_L2"
#  bottom: "heat_weight"
#  top: "weight_stage6_L2"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "loss_stage6_L2"
#  type: "EuclideanLoss"
#  bottom: "weight_stage6_L2"
#  bottom: "label_heat"
#  top: "loss_stage6_L2"
#  loss_weight: 1.0
#}

